# Install

pip install -r requirements

## Install additional nltk tools (or run first_run.py)
    
    python >> import nltk
    python >> nltk.download()
    
and download ``all``



## Dict

    `tokenizing`:
        word tokenizer - spearation by words 
        sentence tokenizer - separataion by sentence
        
    `corpora` - body of text, e.g. speeach, journal body, etc.
    `lexicon` - dictionary; different types due to different kind of usage (scientific, finanace, regular)
    
    
## Lessons (pythonprogramming)

`01.py`

Basic word and sentence tokenizing

`02.py`

This lesson is about stop words. Words thaht to not have any meanig and you can remove them.



 